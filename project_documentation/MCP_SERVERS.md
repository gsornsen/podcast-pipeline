# MCP Servers & Tools Documentation

## ğŸ“‹ Overview

This document catalogs all MCP servers and tools required by the Claude Code subagents identified for the podcast pipeline project. The approach prioritizes local development with optional deployment to the home-k8s infrastructure when persistence or advanced monitoring is needed.

## ğŸ¯ Local-First Development Strategy

- **Primary Environment**: Local development on developer machine
- **Infrastructure**: Optional deployment to `~/git/home-k8s` repo for persistence/monitoring
- **Tooling**: Modern Python ecosystem with uv, ruff, and hatchling
- **Deployment**: ArgoCD manages applications in home k8s cluster

## ğŸ¤– Agent Tool Requirements

### Status Legend

- âœ… **Available**: Tool/server is implemented and ready to use
- ğŸ”§ **Needs Setup**: Tool/server needs installation or configuration
- ğŸš« **Not Needed**: Tool/server not required for this project
- âŒ **Not Available**: Tool/server not implemented and not planned

### Meta-Orchestration Agents (Priority: P1)

#### multi-agent-coordinator

- **Tools Required**: `Read`, `Write`, `message-queue`, `pubsub`, `workflow-engine`
- **Status**:
  - âœ… Read, Write: Available (built-in)
  - âœ… message-queue: RedisMCPServer implemented
  - âœ… pubsub: RedisMCPServer implemented
  - âœ… workflow-engine: temporal-mcp implemented
- **Setup**: Start Redis server (`redis-server`) and Temporal server (`temporal server start-dev)

#### workflow-orchestrator

- **Tools Required**: `Read`, `Write`, `workflow-engine`, `state-machine`, `bpmn`
- **Status**:
  - âœ… Read, Write: Available (built-in)
  - âœ… workflow-engine: temporal-mcp implemented
  - âœ… state-machine: Use Temporal workflows instead
  - ğŸš« bpmn: Not needed for this project
- **Setup**: Start Temporal server (`temporal server start-dev`)

#### context-manager

- **Tools Required**: `Read`, `Write`, `redis`, `elasticsearch`, `vector-db`
- **Status**:
  - âœ… Read, Write: Available (built-in)
  - âœ… redis: RedisMCPServer implemented
  - ğŸš« elasticsearch: Not needed for this project
  - ğŸš« vector-db: Not needed for this project
- **Setup**: Start Redis server (`redis-server`)

#### task-distributor

- **Tools Required**: `Read`, `Write`, `task-queue`, `load-balancer`, `scheduler`
- **Status**:
  - âœ… Read, Write: Available (built-in)
  - âœ… task-queue: taskqueue MCP server implemented
  - ğŸš« load-balancer: Not needed for this project
  - ğŸ”§ scheduler: APScheduler or similar Python library
- **Setup**: Use taskqueue MCP server for task management

#### agent-organizer

- **Tools Required**: `Read`, `Write`, `agent-registry`, `task-queue`, `monitoring`
- **Status**:
  - âœ… Read, Write: Available (built-in)
  - ğŸ”§ agent-registry: Simple JSON/YAML configuration
  - âœ… task-queue: taskqueue MCP server implemented
  - ğŸš« monitoring: Not needed for this project (can use home-k8s if required)
- **Setup**: Use taskqueue MCP server and configuration files

#### performance-monitor

- **Tools Required**: `Read`, `Write`, `MultiEdit`, `Bash`, `prometheus`, `grafana`, `datadog`, `elasticsearch`, `statsd`
- **Status**:
  - âœ… Read, Write, MultiEdit, Bash: Available (built-in)
  - ğŸš« prometheus, grafana: Not needed for this project (available in home-k8s if required)
  - ğŸš« datadog: Not needed for this project
  - ğŸš« elasticsearch: Not needed for this project
  - ğŸš« statsd: Not needed for this project
- **Setup**: Use Python logging for local development

#### error-coordinator

- **Tools Required**: `Read`, `Write`, `MultiEdit`, `Bash`, `sentry`, `pagerduty`, `error-tracking`, `circuit-breaker`
- **Status**:
  - âœ… Read, Write, MultiEdit, Bash: Available (built-in)
  - ğŸ”§ sentry: Can set up locally or use Sentry.io (optional)
  - ğŸš« pagerduty: Not needed for this project
  - ğŸ”§ error-tracking: Simple logging initially
  - ğŸ”§ circuit-breaker: Python circuit breaker libraries
- **Setup**: Use Python logging and circuit breaker patterns

#### knowledge-synthesizer

- **Tools Required**: `Read`, `Write`, `MultiEdit`, `Bash`, `vector-db`, `nlp-tools`, `graph-db`, `ml-pipeline`
- **Status**:
  - âœ… Read, Write, MultiEdit, Bash: Available (built-in)
  - ğŸš« vector-db: Not needed for this project
  - ğŸ”§ nlp-tools: spaCy, NLTK, transformers
  - ğŸš« graph-db: Not needed for this project
  - ğŸ”§ ml-pipeline: Part of core project infrastructure
- **Setup**: Use transformers and NLP libraries for text processing

### Core Development Agents (Priority: P0)

#### python-pro

- **Tools Required**: `Read`, `Write`, `MultiEdit`, `Bash`, `uv`, `pytest`, `ruff`, `mypy`, `bandit`
- **Status**:
  - âœ… Read, Write, MultiEdit, Bash: Available (built-in)
  - âœ… uv: Need to install (`curl -LsSf https://astral.sh/uv/install.sh | sh`)
  - âœ… pytest, ruff, mypy, bandit: Available via uv
- **Setup**: `uv add --dev pytest ruff mypy bandit`

#### ai-engineer

- **Tools Required**: `python`, `jupyter`, `tensorflow`, `pytorch`, `huggingface`, `wandb`
- **Status**:
  - âœ… python: Available (3.13)
  - ğŸ”§ jupyter: Install via uv
  - ğŸ”§ tensorflow: Install via uv if needed (project uses PyTorch)
  - âœ… pytorch: Available in pyproject.toml
  - ğŸ”§ huggingface: Install transformers, datasets libraries
  - ğŸ”§ wandb: For experiment tracking
- **Setup**: `uv add --dev jupyter transformers datasets wandb torch torchaudio`

#### ml-engineer

- **Tools Required**: `mlflow`, `kubeflow`, `tensorflow`, `sklearn`, `optuna`
- **Status**:
  - ğŸ”§ mlflow: Can run locally or in home-k8s
  - âŒ kubeflow: Not needed for local development
  - ğŸ”§ tensorflow: Install if needed
  - âœ… sklearn: Standard ML library
  - ğŸ”§ optuna: Hyperparameter optimization
- **Setup**: `uv add --dev mlflow scikit-learn optuna`

#### data-engineer

- **Tools Required**: `spark`, `airflow`, `dbt`, `kafka`, `snowflake`, `databricks`
- **Status**:
  - âŒ spark: Overkill for local development
  - âŒ airflow: Too heavy for local development
  - ğŸ”§ dbt: Can use for data transformations if needed
  - âŒ kafka: Not needed for local development
  - âŒ snowflake, databricks: Cloud services, not needed locally
- **Setup**: Simple Python scripts for data processing, no external dependencies needed

### Quality Assurance Agents (Priority: P1)

#### code-reviewer

- **Tools Required**: `Read`, `Grep`, `Glob`, `git`, `eslint`, `sonarqube`, `semgrep`
- **Status**:
  - âœ… Read, Grep, Glob, git: Available (built-in)
  - âŒ eslint: JavaScript tool, not needed for Python project
  - ğŸ”§ sonarqube: Can run locally with Docker for advanced analysis
  - ğŸ”§ semgrep: Static analysis tool for security and quality
- **Setup**: `uv add --dev semgrep` for static analysis

#### test-automator

- **Tools Required**: `Read`, `Write`, `selenium`, `cypress`, `playwright`, `pytest`, `jest`, `appium`, `k6`, `jenkins`
- **Status**:
  - âœ… Read, Write: Available (built-in)
  - âŒ selenium, cypress, playwright: Web testing tools, not needed for ML project
  - âœ… pytest: Available
  - âŒ jest: JavaScript testing, not needed
  - âŒ appium: Mobile testing, not needed
  - ğŸ”§ k6: Load testing tool
  - âŒ jenkins: Using local development approach
- **Setup**: `pytest` with coverage for comprehensive testing

#### performance-engineer

- **Tools Required**: `Read`, `Grep`, `jmeter`, `gatling`, `locust`, `newrelic`, `datadog`, `prometheus`, `perf`, `flamegraph`
- **Status**:
  - âœ… Read, Grep: Available (built-in)
  - ğŸ”§ jmeter, gatling, locust: Load testing tools (optional)
  - âŒ newrelic, datadog: Commercial APM tools
  - âœ… prometheus: Available in home-k8s
  - ğŸ”§ perf, flamegraph: Profiling tools
- **Setup**: Python profiling tools (cProfile, py-spy) for local development

#### debugger

- **Tools Required**: `Read`, `Grep`, `Glob`, `gdb`, `lldb`, `chrome-devtools`, `vscode-debugger`, `strace`, `tcpdump`
- **Status**:
  - âœ… Read, Grep, Glob: Available (built-in)
  - ğŸ”§ gdb, lldb: System debuggers (available on Linux)
  - âŒ chrome-devtools: Web debugging, not needed
  - âœ… vscode-debugger: IDE debugging capabilities
  - ğŸ”§ strace, tcpdump: System debugging tools
- **Setup**: Use Python debugger (pdb, ipdb) and IDE debugging

### Infrastructure Agents (Priority: P2)

#### devops-engineer

- **Tools Required**: `Read`, `Write`, `MultiEdit`, `Bash`, `docker`, `kubernetes`, `terraform`, `ansible`, `prometheus`, `jenkins`
- **Status**:
  - âœ… Read, Write, MultiEdit, Bash: Available (built-in)
  - âœ… docker: Available (`/usr/bin/docker`)
  - âŒ kubernetes: Local development approach, available in home-k8s
  - âŒ terraform: Not needed for local development
  - âŒ ansible: Not needed for local development
  - âœ… prometheus: Available in home-k8s
  - âŒ jenkins: Using local development approach
- **Setup**: Docker for containerization, deploy to home-k8s when needed

#### platform-engineer

- **Tools Required**: `Read`, `Write`, `MultiEdit`, `Bash`, `kubectl`, `helm`, `argocd`, `crossplane`, `backstage`, `terraform`, `flux`
- **Status**:
  - âœ… Read, Write, MultiEdit, Bash: Available (built-in)
  - âœ… kubectl, helm, argocd: Available in home-k8s environment
  - ğŸ”§ crossplane: Available in home-k8s for infrastructure composition
  - ğŸ”§ backstage: Developer portal (optional)
  - âŒ terraform: Not using for local development
  - ğŸ”§ flux: GitOps tool (argocd is primary choice)
- **Setup**: Connect to home-k8s cluster when needed for deployment

### Specialized Domain Agents (Priority: P2)

#### nlp-engineer

- **Tools Required**: `Read`, `Write`, `MultiEdit`, `Bash`, `transformers`, `spacy`, `nltk`, `huggingface`, `gensim`, `fasttext`
- **Status**:
  - âœ… Read, Write, MultiEdit, Bash: Available (built-in)
  - âœ… transformers: Available via huggingface
  - ğŸ”§ spacy: Advanced NLP library
  - ğŸ”§ nltk: Natural language toolkit
  - âœ… huggingface: Model hub access
  - ğŸ”§ gensim: Topic modeling
  - ğŸ”§ fasttext: Text classification
- **Setup**: `uv add --dev transformers spacy nltk gensim`

#### prompt-engineer

- **Tools Required**: `openai`, `anthropic`, `langchain`, `promptflow`, `jupyter`
- **Status**:
  - ğŸ”§ openai: API client for OpenAI models
  - ğŸ”§ anthropic: API client for Claude
  - ğŸ”§ langchain: LLM application framework
  - ğŸ”§ promptflow: Microsoft prompt engineering tool
  - âœ… jupyter: Available for experimentation
- **Setup**: `uv add openai anthropic langchain` Add jupyter to --dev if not already present

## ğŸš€ Setup Priority & Implementation Plan

### Phase 0: Essential Local Development (Immediate)

```bash
# Install uv (modern Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install core development dependencies
uv add --dev pytest ruff mypy bandit pre-commit

# Install ML/AI dependencies for voice processing
uv add torch torchaudio transformers datasets librosa soundfile

# Install experiment tracking
uv add --dev wandb mlflow

# Install data processing
uv add --dev pandas numpy scipy matplotlib seaborn

# Install web framework for APIs/UIs
uv add fastapi uvicorn pydantic
```

### Background Services Setup

For agents requiring external services, start these background processes:

```bash
# Redis server (required for RedisMCPServer) try without starting it first, as there may be a redis/valkey instance already available
$ redis-cli -u redis://localhost:6379
localhost:6379> ping
PONG
localhost:6379>
# Start redis-server only if necessary

# Temporal server (required for temporal-mcp)
temporal server start-dev

# Optional: Use tmux/screen to manage background services
tmux new-session -d -s redis 'redis-server'
tmux new-session -d -s temporal 'temporal server start-dev'
```

### Phase 1: Quality & Testing Tools (Week 1)

```bash
# Static analysis and security
uv add --dev semgrep safety

# Advanced testing
uv add --dev pytest-cov pytest-xdist hypothesis

# Performance profiling
uv add --dev py-spy memory-profiler line-profiler

# Documentation
uv add --dev mkdocs mkdocs-material
```

### Phase 2: Optional Infrastructure (Week 2-3)

```bash
# Local development services with Docker
docker run -d --name redis -p 6379:6379 redis:alpine
docker run -d --name mlflow -p 5000:5000 -v mlflow_data:/mlflow python:3.13 mlflow server --host 0.0.0.0

# Advanced NLP tools
uv add --dev spacy nltk gensim
uv run python -m spacy download en_core_web_sm

# Vector database for knowledge management
uv add chromadb faiss-cpu
```

### Phase 3: Home-K8s Integration (As Needed)

When persistent storage, monitoring, or team collaboration is needed:

1. **MLflow**: Deploy to home-k8s for experiment persistence
2. **Prometheus/Grafana**: Use existing monitoring stack
3. **Redis**: Use for caching and pub/sub
4. **ArgoCD**: Deploy applications to cluster

## ğŸ”§ MCP Server Requirements

### Custom MCP Servers (Development Status)

1. **Workflow Engine MCP Server** âœ…
   - Purpose: State machine and workflow orchestration
   - Implementation: temporal-mcp (implemented)
   - Status: Available - requires `temporal server start-dev`

2. **Message Queue MCP Server** âœ…
   - Purpose: Inter-agent communication
   - Implementation: RedisMCPServer (implemented)
   - Status: Available - requires `redis-server`

3. **Task Queue MCP Server** âœ…
   - Purpose: Task distribution and coordination
   - Implementation: taskqueue (implemented)
   - Status: Available

4. **ML Tools MCP Server** ğŸ”§
   - Purpose: MLflow, model registry, experiment tracking
   - Implementation: MLflow API wrapper
   - Status: Not yet needed - can implement when M1 training phase requires it

### Available MCP Servers

1. **Notion MCP Server** âœ…
   - Status: Already connected
   - Purpose: Documentation and knowledge management

2. **Hugging Face MCP Server** âœ…
   - Status: Available
   - Purpose: Model and dataset discovery

3. **Canva MCP Server** âœ…
   - Status: Connected
   - Purpose: Design and visual content creation

4. **Jam MCP Server** âœ…
   - Status: Connected
   - Purpose: Bug reporting and issue tracking

5. **taskqueue MCP Server** âœ…
   - Status: Implemented
   - Purpose: Task queue management and coordination

6. **temporal-mcp MCP Server** âœ…
   - Status: Implemented
   - Purpose: Workflow orchestration and state management
   - Note: Requires Temporal server (`temporal server start-dev`)

7. **RedisMCPServer** âœ…
   - Status: Implemented
   - Purpose: Message queuing, pub/sub, and caching
   - Note: Requires Redis server (`redis-server`)

8. **playwright MCP Server** âœ…
   - Status: Implemented
   - Purpose: Web automation and testing

9. **github MCP Server** âœ…
   - Status: Implemented
   - Purpose: GitHub repository management and operations

## ğŸ“Š Tool Availability Matrix

| Tool Category | Tool | Status | Setup Required | Priority |
|---------------|------|--------|----------------|----------|
| **Python Ecosystem** | uv | ğŸ”§ | Install script | P0 |
| | ruff | âœ… | Via uv | P0 |
| | pytest | âœ… | Via uv | P0 |
| | mypy | âœ… | Via uv | P0 |
| | bandit | âœ… | Via uv | P0 |
| **ML/AI Tools** | pytorch | âœ… | In pyproject.toml | P0 |
| | transformers | ğŸ”§ | Via uv | P0 |
| | wandb | ğŸ”§ | Via uv | P1 |
| | mlflow | ğŸ”§ | Via uv or home-k8s | P1 |
| **MCP Servers** | temporal-mcp | âœ… | Temporal server required | P1 |
| | RedisMCPServer | âœ… | Redis server required | P1 |
| | taskqueue | âœ… | Ready to use | P1 |
| | playwright | âœ… | Ready to use | P2 |
| | github | âœ… | Ready to use | P2 |
| | huggingface | âœ… | Ready to use | P1 |
| **Infrastructure** | docker | âœ… | System installed | P1 |
| | redis-server | ğŸ”§ | System install or Docker | P1 |
| | temporal | ğŸ”§ | Install temporal CLI | P1 |
| | prometheus | ğŸš« | Not needed (available in home-k8s) | P2 |
| | grafana | ğŸš« | Not needed (available in home-k8s) | P2 |
| **Quality Tools** | semgrep | ğŸ”§ | Via uv | P1 |
| | pre-commit | âœ… | In pyproject.toml | P1 |
| **Development** | jupyter | ğŸ”§ | Via uv | P1 |
| | git | âœ… | System installed | P0 |

## ğŸ  Home-K8s Integration Points

The `~/git/home-k8s` repository provides production infrastructure for:

### Available Services

- **ArgoCD**: Application deployment and GitOps
- **Prometheus/Grafana**: Metrics and monitoring
- **OTEL**: Distributed tracing
- **Redis**: Caching and pub/sub messaging
- **Storage**: Persistent volumes for data

### Integration Strategy

1. **Local Development**: Use lightweight alternatives (Docker, file storage)
2. **Persistence Needed**: Deploy MLflow, databases to home-k8s
3. **Team Collaboration**: Use home-k8s for shared services
4. **Production Workloads**: Scale up model training in cluster

### Deployment Process

```bash
# From podcast-pipeline project
cd ~/git/home-k8s

# Create application manifests for podcast-pipeline
kubectl apply -f applications/podcast-pipeline/

# Monitor deployment via ArgoCD
# Access Grafana for monitoring
# Use cluster resources for training large models
```

## ğŸ“ Next Steps

1. **Immediate**: Install uv and core Python dependencies
2. **Week 1**: Set up quality tools and testing infrastructure
3. **Week 2**: Add ML/AI tools for model training (M1 phase)
4. **Week 3**: Integrate with home-k8s for persistence and monitoring
5. **Ongoing**: Develop custom MCP servers as coordination needs grow

## ğŸ” Notes

- **Local-First**: Prioritize tools that work well in local development
- **Kubernetes Optional**: Use home-k8s for persistence, monitoring, and scaling
- **Tool Evolution**: Start simple, add complexity as project grows
- **Agent Flexibility**: Agents adapt to available tools, graceful degradation when tools unavailable
- **Cost Efficiency**: Avoid commercial services where open-source alternatives exist
- **Development Velocity**: Choose tools that enhance rather than hinder development speed

---

*This document should be updated as new MCP servers are developed and integrated into the project.*
